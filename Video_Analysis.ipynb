{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb54fda-b74f-4da8-afea-0b3afb8f086a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction:\n",
    "\n",
    "This Python script utilizes Google Gemini, a multimodal LLM (Large Language Model), to analyze a video and identify scene changes, specifically focusing on detecting potential points for ad insertion. The script prompts Gemini to select the 10 most suitable scene transitions across the video, distributing them throughout the beginning, middle, and end. These points are chosen to minimize interruptions for viewers and ensure optimal ad placement.\n",
    "\n",
    "The Gemini model provides metadata for each identified scene change, including the timestamp, reason for the scene change, summary, transition type, narrative role, dialogue intensity, and character types. This metadata is returned in a consistent JSON structure, thanks to Gemini's controlled output feature, making it suitable for downstream processing without additional transformations. The script converts this structured JSON response into a Pandas DataFrame for storage in a database like BigQuery for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6686ab-3e09-4559-9bf2-f348fd9fe56f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import vertexai  # Import the Vertex AI library for initializing and using the Gemini model\n",
    "from google.cloud import storage  # Google Cloud Storage client for handling GCS\n",
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,        # Configuration settings for Gemini's response generation\n",
    "    GenerativeModel,         # Class representing the generative model used for generating responses\n",
    "    Part,                    # Used to define parts of multimodal content like videos\n",
    "    Content,                 # Represents the content used in the generation request\n",
    "    GenerationResponse,      # Structure to handle the response from Gemini\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0adc2d-8ecf-4aff-9612-d49ae7af0e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the GCP project and location where Vertex AI is being used\n",
    "project_id = \"lab-project-426319\"#\"[project-id]\"\n",
    "location = \"us-central1\"\n",
    "\n",
    "# Initialize Vertex AI with the project ID and location to use the Gemini model\n",
    "vertexai.init(project=project_id, location=location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "604301a2-4f95-4fe8-879f-9b58d79011e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt that will be sent to Gemini.\n",
    "# This prompt explains the task to analyze the video and identify the best scene changes for ad placement.\n",
    "prompt = '''\n",
    "       I have a video that I need you to analyze for ad placement by detecting scene changes, \n",
    "       also known as shot boundaries. I need to identify the 10 best scene changes across the \n",
    "       entire movie, which are the best potential points for ad placement as they minimize \n",
    "       interruptions for viewers. These scene changes should be selected from all parts of the movie: \n",
    "       the beginning, middle, and the very end. Make sure you distribute the selected scenes evenly across \n",
    "       the entire movie.\n",
    "       For each of these scene changes, please provide:\n",
    "\n",
    "        timestamp: The exact timestamps indicating where the scene change occurs. Make sure that the timestamp of scenes are matched those in the original movie,\n",
    "        reflecting its position accurately. The timestamps must exactly match those in the original movie.\n",
    "        \n",
    "        reason: The reason why this is a scene change and why it is a good location for ad placement. the reason \n",
    "        should be very specific. Summarize the story after and before the scene and explain why \n",
    "        between these two scenes is a good place for an ad.\n",
    "        \n",
    "        summary: A brief summary of the scene before the change.\n",
    "        \n",
    "        transition_feeling: The main feeling that the transition makes in viewers like excitement, peace, fear, etc.\n",
    "        \n",
    "        transition_type: The method used to switch from one scene to another like cuts, fades, dissolves, etc.\n",
    "        \n",
    "        narrative_type: The main role or significance of the scene in the storyline like pivotal, climatic, conflict, etc.\n",
    "        \n",
    "        dialogue_intensity: The amount and intensity of dialogue in the scene like monologue, dialogue, narration, debate, etc.\n",
    "\n",
    "        characters_type: The types of the most important character involved in the scene transition like protagonist, antagonist, supporting, etc.\n",
    "        \n",
    "        scene_categories:  Classification of the scene before the change into the categories such as action, drama, comedy, etc.\n",
    "      '''      \n",
    "\n",
    "# Define the expected response schema to ensure the output JSON is structured correctly\n",
    "response_schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"timestamp\": {\"type\": \"string\"},\n",
    "            \"reason\": {\"type\": \"string\"},\n",
    "            \"transition_feeling\": {\"type\": \"string\"},\n",
    "            \"transition_type\": {\"type\": \"string\"},\n",
    "            \"narrative_type\": {\"type\": \"string\"},\n",
    "            \"dialogue_intensity\": {\"type\": \"string\"},\n",
    "            \"characters_type\": {\"type\": \"string\"},\n",
    "            \"scene_categories\": {\"type\": \"string\"},\n",
    "        },\n",
    "        # Ensure that these properties are always present in the output\n",
    "        \"required\": [\"timestamp\", \"reason\",\"transition_feeling\",\"transition_type\",\"narrative_type\",\n",
    "                    \"characters_type\",\"scene_categories\"],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda69fbe-4f73-4125-a3f4-209f3468dcd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the version of the Gemini model to be used\n",
    "model_id = \"gemini-1.5-pro-001\"  \n",
    "model = GenerativeModel(model_id)\n",
    "\n",
    "# Set up the generation configuration to control Gemini's response\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0,  # Set the temperature to 0 for consistent output\n",
    "    response_mime_type=\"application/json\",  # Expect the response to be in JSON format\n",
    "    response_schema=response_schema  # Use the predefined response schema for structured output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a6a0b6-7b7a-4638-9e79-06cc048308d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the URL of the video file stored in Google Cloud Storage\n",
    "video_file_url = 'gs://video_demo_test/wakeup_princess.mp4'\n",
    "\n",
    "# Load the video file from Google Cloud Storage as an input to Gemini\n",
    "video_file = Part.from_uri(video_file_url, mime_type=\"video/mp4\")\n",
    "\n",
    "# Combine the video file and the prompt into a single input to the Gemini model\n",
    "contents = [video_file, prompt]\n",
    "\n",
    "# Generate content from Gemini by passing the contents and the generation configuration\n",
    "response = model.generate_content(contents, generation_config=generation_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3ec957-03b6-42f1-abcd-b04befc18494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the JSON response from Gemini into a Python dictionary\n",
    "json_response = json.loads(response.text)\n",
    "\n",
    "# Convert the JSON response into a Pandas DataFrame for easier analysis and storage\n",
    "df_response = pd.DataFrame(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b492a-b0b6-4b32-bfe3-51af1231f9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m122"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
